# 一、为什么要使用缓存

在互联网后端系统应用场景中，我们一般会把数据存储在如MySQL等关系型数据库中。毫秒级的数据库响应时间在访问量较低的情况下可以很好的完成工作，但对于动辄上百万QPS的用户端服务来说，数据库的性能就会成为服务性能的瓶颈。

互联网服务中有下面这些常见的场景：

- 数据不常变动，访问却很频繁
- 相同数据的查询及计算逻辑被重复执行
- 数据可能已经被存储在某个地方

如果用户的每一次访问都通过查库来获取数据，必然会造成不必要的资源浪费和性能损失。于是我们通过在应用程序和数据库之间加入一级或多级缓存来解决这一问题，在用户请求的若干个环节中从缓存直接获取数据，从而减少计算量，减轻服务器负担有效提升响应速度。

# 二、缓存的层次

## CDN

**什么是CDN**

CDN（内容分发网络）全称是 Content Delivery Network，建立并覆盖在承载网之上、由分布在不同区域的边缘节点服务器群组成的分布式网络，替代传统以 WEB Server 为中心的数据传输模式。

作用是将源内容发布到边缘节点，配合精准的调度系统；将用户的请求分配至最适合他的节点，使用户可以以最快的速度取得他所需的内容，有效解决Internet网络拥塞状况，提高用户访问的响应速度。

**CDN的基本工作过程**

用户通过浏览器等方式访问网站的过程如图所示

1. 用户在自己的浏览器中输入要访问的网站域名。
2. 浏览器向 本地DNS服务器 请求对该域名的解析。
3. 本地DNS服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。
4. 本地DNS服务器中如果没有关于这个域名的解析结果的缓存，则以递归方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器。
5. 浏览器得到域名解析结果，就是该域名相应的服务设备的 IP地址 。
6. 浏览器向服务器请求内容。
7. 服务器将用户请求内容传送给浏览器。

**适用场景**

1. 网站站点/应用加速
2. 视音频点播/大文件下载分发加速
3. 视频直播加速
4. 移动应用加速

## 页面缓存

**页面HTML的缓存**

浏览器在对资源的第一次请求之后，会把资源的一部分存储在计算机的临时文件空间，当再次请求的时候，按照特定的策略加载缓存中的资源，从而减少http请求的次数与传输的数据量，提高了浏览效率，极大减少服务器压力。

**如何控制页面缓存**

页面缓存状态是由http header决定的，一个浏览器请求信息，一个是服务器响应信息。主要包括Pragma: no-cache、Cache-Control、 Expires、 Last-Modified、If-Modified-Since。其中Pragma: no-cache由HTTP/1.0规定，Cache-Control由HTTP/1.1规定。第一次请求时，浏览器通过http的header报头，附带Expires，Cache-Control，Last-Modified/Etag向服务器请求，此时服务器记录第一次请求的Last-Modified/Etag再次请求。当浏览器再次请求的时候，附带Expires，Cache-Control，If-Modified-Since/Etag向服务器请求。服务器根据第一次记录的Last-Modified/Etag和再次请求的If-Modified-Since/Etag做对比，判断是否需要更新，然后响应请求。

相关参数说明：

| **参数名**        | **参数值**                                                   | **作用**                                |
| ----------------- | ------------------------------------------------------------ | --------------------------------------- |
| Cache-Control     | public                                                       | Public 响应会被缓存，并且在多用户间共享 |
| private           | Private 响应只能够作为私有的缓存，不能再用户间共享           |                                         |
| no-cache          | 不进行缓存                                                   |                                         |
| max-age=x         | 缓存时间 以秒为单位                                          |                                         |
| must-revalidate   | 如果页面是过期的 则去服务器进行获取                          |                                         |
| Expires           | 显示的设置页面过期时间                                       |                                         |
| Last-Modified     | 请求对象最后一次的修改时间 用来判断缓存是否过期 通常由服务器上文件的时间信息产生 |                                         |
| If-Modified-Since | 客户端发送请求附带的信息 指浏览器缓存请求对象的最后修改日期 用来和服务器端的Last-Modified做比较 |                                         |
| Etag              | ETag是一个可以 与Web资源关联的记号（token），和Last-Modified功能才不多，也是一个标识符，一般和Last-Modified一起使用，加强服务器判断的准确度 |                                         |

**图片/css/js/flash的缓存**

主要通过服务器的配置来实现这个技术，如果使用apache服务器的话，可以使用mod_expires模块来实现。同样可以用nginx方式实现前端页面缓存。当页面加载了 a.jpg 和 a.jpg?v=1 时，会当作两个文件，都是去拉服务器最新资源，只有加载资源的url，完全一致才会走缓存

## 分布式缓存

高并发环境下，大量的读写请求涌向数据库，磁盘的处理速度与内存显然不在一个量级，从减轻数据库的压力和提高系统响应速度两个角度来考虑，一般都会在数据库之前加一层缓存。由于单台机器的内存资源以及承载能力有限，并且，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，才催生出了分布式缓存，目前比较成熟的分布式缓存方案有Redis、MemCache、SSDB等。分布式缓存要解决的最主要的两个问题就是数据分片和数据冗余，何为数据分片（segment，fragment， shard， partition），就是按照一定的规则，将数据集划分成相互独立、正交的数据子集，然后将数据子集分布到不同的节点上。

##### 三种数据分片方式

数据分片是把数据均匀分散到多个实例中。数据分片可以采用以下几种规则：hash分片和range based。对于hash分片，主要的哈希算法有静态哈希和一致性哈希

**静态hash**

数据分片的静态hash，即按照数据的某一特征（key）来计算哈希值，并将哈希值与系统中的节点建立映射关系,从而将哈希值不同的数据分布到不同的节点上。

**一致性hash**

一致性hash算法在1997年由麻省理工学院的Karger等人在解决分布式缓存中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，现在一致性hash算法在分布式缓存中得到了广泛应用，

**range based**

简单来说，就是按照关键值划分成不同的区间，每个物理节点负责一个或者多个区间。其实这种方式跟一致性hash有点像，可以理解为物理节点在hash环上的位置是动态变化的。

对于四种分片方式（有virtual node和没有virtual node的一致性hash算两种）进行简单总结，主要是针对提出的几个问题：

| **数据分片方式**     | **映射难度** | **元数据**                                           | **节点删减**                                                 |
| -------------------- | ------------ | ---------------------------------------------------- | ------------------------------------------------------------ |
| 静态hash             | 简单         | 非常简单，几乎不用修改                               | 需要迁移的数据比较多                                         |
| 一致性hash无虚拟节点 | 简单         | 比较简单，取决于节点规模，几乎不用修改               | 增删节点的时候只影响hash环上相邻节点，但不能使所有节点都参与数据迁移过程 |
| 一致性hash有虚拟节点 | 中等         | 稍微复杂一些，主要取决于虚拟节点规模，很少修改       | 需要迁移的数据比较少，且所有节点都能贡献部分数据             |
| range based          | 较为复杂     | 取决于每个块的大小，一般来说规模较大；且修改频率较高 | 需要迁移的数据比较少，且所有节点都能贡献部分数据             |

## 内存缓存

应用中的热点数据访问非常频繁，一般使用内存缓存来存储这些数据，堆缓存是我们常用的内存缓存。存储访问堆缓存对象时，无需进行序列化和反序列化，没有网络开销等，是最快的缓存。

但堆缓存的存储容量受限于堆空间大小，当缓存的数据量很大时，垃圾回收的时间会变长。常用Guava Cache、EhCache等实现。

**EhCache**

Ehcache是一个用Java实现的使用简单，线程安全的缓存管理类库。Ehcache具有快速、简单、低消耗、依赖性小等特点，遵循Apache 2.0 license。官网<http://www.ehcache.org/>

主要特点

- 快速，简单

过去众多测试已经证明Ehcache是最快的Java缓存之一，Ehcache的线程机制是为大型高并发系统设计的，不需要复杂的配置，API也便于使用，很容易部署上线和运行。

- 支持多种缓存策略

提供LRU,LFU,FIFO的缓存策略。支持基于cache和基于element的过期策略，每个cache的存活时间都是可以设置和控制的。

- 缓存数据有两级

内存和磁盘，因此无需担心容量问题。缓存在内存和磁盘存储可以伸缩到GB，在大内存的情况下，所有进程可以支持数百GB的吞吐，在单台虚拟机可以支持多缓存管理器，还可以通过terracotta服务器矩阵伸缩到数百个节点。

- 缓存数据会在机器重启的过程中写入磁盘

Ehcache是第一个引入缓存数据持久化存储的开源Java缓存框架，缓存的数据可以在机器重启后从磁盘上重新获得，可以根据需要使用cache.flush方法将缓存刷到磁盘上面，极大地方便了Ehcache的使用。

- 可以进行分布式缓存

- 具有缓存管理器和监听器

- 提供hibernate的缓存实现

**Guava Cache**

Guava 是Google提供的一套Java工具包，而Guava Cache作为Guava的Cache部分而提供非常完善的本地缓存机制。Guava Cache是一个基于全内存的本地缓存实现，它提供了线程安全的实现机制。

适用场景

・希望花费一些内存来提高速度

・keys会被多次查询

・cache保存的东西不会超过机器的内存量

# 三、缓存常见问题 

## 缓存预热 

缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询事先被预热的缓存数据。 

常用的解决方案有： 

1. 定时任务定时刷新缓存 
2. 直接写个缓存刷新页面，上线时手工操作下 
3. 数据量不大，可以在项目启动的时候自动进行加载 

## 缓存雪崩 

缓存雪崩是指大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 

![img](https://s2.ax1x.com/2019/02/25/k5IcWj.png) 

解决方案主要有两种： 

1. **缓存时间增加随机值。**可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效。 
2. **加锁排队。**这种方式适用于并发量不是很多的情况。在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如采用互斥锁，在访问key之前，采用Redis的SETNX（set if not exists）来设置另一个短期互斥key来锁住当前key的访问，访问结束再删除该短期互斥key。 

## 缓存穿透 

缓存穿透的概念是，访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。 

![img](https://s2.ax1x.com/2019/02/25/k5I6YQ.png) 

解决方案有： 

1. **空值缓存。**访问key未在DB查询到值，也将空值写进缓存，为了防止过多占用内存可以设置较短过期时间。 
2. **bloom filter。**采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 

## 缓存更新 

缓存是有容量上限的。当需要缓存的数据量超过这个上限时，需要通过一定的策略来淘汰部分缓存数据。除了为缓存设置失效时间以外，常用的淘汰算法有以下几种： 

1. FIFO，先进先出。存入时间最早的数据优先被淘汰； 
2. LRU，最近最少使用，最近使用时间最早的数据优先被淘汰； 
3. LFU，最不经常使用，一段时间内使用次数最少的优先被淘汰。 

具体采用哪一种策略，需要结合实际情况确定。如果缓存没有明显的热点数据，可以使用 FIFO，甚至是随机淘汰策略，成本较低；如果缓存有明显的热点数据，可以考虑使用 LFU 或 LRU，避免热点数据淘汰。 

我们平时工作中最常用的缓存设计模式被称为 Cache-Aside Pattern。 对于读请求，首先检查缓存中是否有指定值，如果有则返回缓存值作为结果，否则先从 DB 查询出值，把该值写入缓存，最后返回。 

![img](https://s2.ax1x.com/2019/02/25/k5IrTS.png) 

对于写请求，首先更新数据库，然后移除缓存。 

![img](https://s2.ax1x.com/2019/02/25/k5IDw8.png) 

这里有两个问题值得注意： 

1. 为什么是先操作数据库再操作缓存，而不是相反的顺序? 
2. 为什么直接移除（delete）缓存而不是更新（set）缓存？ 

对于第一个问题，我们知道，为了保证更新操作的正确性，需要将多个操作作为一个事务处理。而数据库和缓存处于一个分布式系统中，要保证业务正确性，需要应用分布式事务，逻辑会变得非常复杂。如果不使用分布式事务，则可能出现不一致。在这个场景下，导致不一致的主要是第一步成功，第二步失败的情况，我们不妨分析下两种顺序在不一致状态下的影响： 

1. 先操作数据库成功，移除缓存失败：会导致数据库中是新数据，缓存中是旧数据。在缓存未失效时，业务上是错误的；缓存失效后会读取数据库数据，业务恢复正常。所以出错时要想恢复业务，只需要使缓存失效即可。 
2. 先操作缓存成功，更新数据库失败：会导致缓存中是新数据，数据库中是旧数据。在缓存未失效时，业务上是正确的；但缓存失效后数据会丢失，业务出现错误。此时要恢复业务就比较困难 

可以看到，两种不一致状态都会导致特定情况下业务的异常，但相比较而言，数据库数据有持久化，出错时恢复成本低，所以选择先操作数据库。 对于第二个问题，如果移除缓存，在下一次读取时会因为无缓存直接取一次数据库。如果更新缓存，当出现并发写缓存时，可能会出现脏数据，导致业务错误。所以移除缓存比更新缓存更适合。 

除此之外，还可以使用消息机制或定时任务来作为辅助的缓存更新手段，降低潜在的缓存不一致的风险。 

## 缓存降级 

在应对短期的爆发性增长的流量时，我们通常会对部分低优先级服务做降级处理，以保障核心业务链路正常。例如大促期间，用户更关注他需要的商品是否能够成功加购、下单，而不关心页面上推荐的个性化内容，此时可以考虑对个性化内容服务进行降级，减轻系统压力。在某些场景下，由于降级导致数据缺失，可能会出现影响页面展示等情况。此时可以通过缓存来降低降级带来的影响。 

![img](https://s2.ax1x.com/2019/02/25/k5IyFg.png) 

业务逻辑可以简单由上图描述。 

1. 在获取数据时，先检查当前是否处于降级状态； 
2. 未降级时，走正常业务逻辑获取数据。这一步中可以从缓存读取数据，也可以将从其它服务获取的数据作为降级数据写入缓存 
3. 降级时，直接从缓存获取降级数据 
4. 另外，除了使用「最近成功的请求结果」作为降级数据外，还可以通过定时任务提前构建降级数据。 

使用缓存做业务降级的好处是，一方面从缓存读取数据，相比正常逻辑降低了系统开销，起到了降级的作用，另一方面，相比直接返回空数据或 mock 数据，使用缓存数据更贴近原逻辑，尽可能地减轻了降级对业务的影响。 

值得注意的是，当缓存失效后，由于业务已降级，所以不能再请求真实数据补充到缓存中，仍然会出现无数据的情况。为了降低这种情况发生的概率，通常会对这类数据设置相对较长的失效时间，同时为避免因缓存达到上限而被缓存系统回收，这类数据不宜过多。 

## 缓存暴增 

缓存暴增是一个在本地缓存中容易发生的问题。先来看一个例子： 

```jav
public class ClassA {
    public static int n = 10;
    // ...
}
```

在上面这段代码中 `ClassA` 暴露了一个静态变量 `n`，外部可以引用该对象的值。预期中该值是一个常量，但因为未用 `final` 修饰，如果有一段代码修改了该值，那么其它引用该值的逻辑都会发生错误。那么，是不是使用 final 就可以高枕无忧了呢？再来看一个例子： 

```java
public class ClassA {
    public static final List<Long> validIds = new ArrayList<>();
    static {
        validIds.add(1L);
       // ...
    }
}
```

这段代码中 `validIds` 使用了 `final` 修饰，但由于外部代码可以向 validIds 中增加或删除值，所以 validIds 实际上是会变的。 在分布式缓存中，因为需要进行网络传输，从缓存中获取的对象都是反序列化而来，每个请求（线程）拿到的缓存对象是不同的。但在本地缓存的实现中，很多缓存将数据直接存在堆内存中，每次取出缓存时拿到的缓存对象都是同一个，这时一个线程对缓存对象的修改，其它线程也会感知到。而如果被修改的对象中包含一个集合，每个请求都会向集合中插入元素，最终会导致缓存膨胀。来看下面一段改编自线上真实问题的代码： 

```java
public class FooBean {
    private Long id;
    private List<Long> list;
    //...
}
public class FooService {
    //...
    public void foo() {
        List<Long> idToUpdate = getIdToUpdate();    // 获取待更新对象的 ID
        Map<Long, List<Long>> map = new HashMap<>();    // 根据对象 ID 收集 List
        for (Long id: idToUpdate) {
             FooBean bean = getFromLocalCache(id);   // 从本地缓存获取对象
             if (map.containsKey(id)) {
                 map.get(id).addAll(bean.getList());
             } else {
                 map.put(id, bean.getList());
             }
        }
    }
}
```

这段代码中 `FooService.foo()` 方法的预期的逻辑是，获取一批 ID，根据 ID 从缓存中获取 bean，并将 bean 中的 List 属性按照 ID 收集到一个 Map 中。乍一看好像没有什么问题，但实际运行一段时间之后，这段代码可能会抛出 OOM。那么问题出在哪里呢？  

仔细分析代码，在 if 语句中，如果 map 不包含指定 ID，则直接将 FooBean 中的 list 属性存到 map 中，此时 map 中的 List 对象实际上和本地缓存中 bean 的 list 属性是同一个对象。如果 idToUpdate 中恰好存在了重复的 ID，那么再次进行 if 判断时会进入第一个分支，先从 map 中获取 List 对象，再把 bean 的 list 属性中的所有元素加到该对象中，这个行为的本质就变成 `list.addAll(list)`，相当于 list 的 size 翻倍。如果单次执行中一个 ID 重复出现了 n 次，这个 ID 对应的 bean 的 list 属性 size 会膨胀为原来的 2n-1 倍。当多次调用后，本地缓存很快会因为 list 过大导致 OOM。这种问题排查起来相对较困难。问题的表征是像缓存中写入了大量的数据，但在这段代码中，没有任何显式的「写缓存」动作。即使抛出异常时定位到了 addAll 这一行，也很容易让人不明所以。 

这个问题的本质是，不同线程从本地缓存获取的对象是同一个，同时存在修改属性的操作。要彻底避免这类问题，有几种简单的思路： 

1. 线程从本地缓存获取的对象替换为缓存对象的副本，这样可以隔离线程间缓存对象的影响，同时线程中任何改动都不会影响缓存对象。这种做法的缺点是需要付出额外的对象拷贝成本。 
2. 本地缓存数据序列化存储，读取时进行反序列化。和上一种思路一样做到了线程隔离，同时改动不影响缓存；缺点是额外的序列化开销，常见的本地缓存框架在内存中不支持序列化，如 Ehcache 仅在缓存数据持久化到磁盘时会使用序列化； 
3. 从本地缓存获取的对象替换为代理对象，使 set 方法抛出异常，同样有额外的开销，缓存框架不提供原生支持； 
4. 加入缓存的对象的集合类型属性使用不可变集合，避免意外的修改。 

在这几种思路中，前三种思路有相似之处，都是通过为每个线程返回不同于缓存内部的对象来避免对缓存的意外操作。虽然从源头上避免了问题的发生，但是提升了成本，同时引入了新的复杂性。方案四能解决上面例子中缓存暴增的问题，但无法避免对其它的修改导致业务逻辑错误的问题。需要视具体业务场景来挑选解决方案，如对性能要求更高，逻辑简单的场景，可以使用第四种思路；对性能没那么敏感，但对正确性要求更高的场景则可以考虑前三种方案。

# 四、缓存选型

### 1、各类缓存的使用场景

#  

一般情况下，对QPS要求较高的大型分布式应用，上述的缓存类型都会被使用到。 不同的缓存类型有着不同的特性，而这些特性也基本确定了此类缓存适合于怎样的业务场景。

CDN和页面缓存主要应用于web服务，用于构建高性能的页面服务。

#### **cdn缓存：**

#  

**优点：**用户可以就近访问距离最近、网络连通性最好、负载最低的缓存服务器获取内容。解决了不同地域、不同网络访问站点时的性能不一致情况，同时减少了源站的访问压力。

**缺点：**需要在源站之外部署多个缓存服务器提高性能，成本较高，且优化能力与负载均衡算法效果直接挂钩。

**适应场景：**用户量大、分布较广，用户使用的网络情况复杂的场景，且对资源的响应速度要求较高；一般用于缓存通用的页面静态资源(如js等)。

#### **页面缓存：主要为nginx local cache**

**优点：**nginx具有优异的高并发支持特性，可以用较低的成本实现高并发

**缺点：**nginx local cache支持的协议少（http、https & email），并且只适合用作静态页面缓存。

**适应场景：**主要用于对静态页面的高并发访问时提供缓存。

 

内存缓存和分布式缓存则更具通用性，所有后端服务都可能使用到。但内存缓存和分布式缓存的特性差异较大，在使用中要特别注意。

#### **内存缓存：**

**优点：**本机内存访问，速度最快，无网络开销。

**缺点：**受限于服务器内存，容量较小。由于上层负载均衡策略影响，命中率比较难控制。缓存效果与缓存算法、超时时间等配置直接相关。

**适应场景：**超高并发场景下的少量热点数据缓存

#### **分布式缓存：**

#  

**优点：**在对内以集群形式提供高可用的前提下，对客户端提供了一个近似单点的缓存服务，功能强大，可以支持几乎所有的缓存功能：临时持久化工具、锁管理、开关配置等等。较DB而言，内存读取较磁盘读取更快，redis集群并发支持较db更高（一般DB不会使用集群，且DB成本更高）

**缺点：**数据一致性等特性需要代码的相关开发。并且对超高并发场景支持需要较高成本

**适应场景：**并发量可控的一切缓存场景。

 

### 2、考拉活动页业务缓存使用场景 

#  

接下来就结合考拉活动页的缓存业务，对缓存选型做个说明：

**问题1**、**访问活动页时的加载时间太长了，每次访问感觉都很慢，崩溃！**

原因：请求似乎都直接访问到后端了，每次都从服务端重新加载数据，能不慢嘛？

解决方案：加上页面访问，通过nginx配置两种访问类型，需要千人千面动态加载的页面采用.html访问，直接请求后端。千人一面的静态页面通过.shtml访问，直接在nginx层返回数据。

结果：shtml访问性能较html直接提高了十多倍，还减轻了服务器的访问压力。

 

**问题2、访问考拉活动页香港站的时候页面渲染很慢，等图片加载感觉等了一个世纪！**

原因：用户就是图片和js等文件加载慢，但开发自测试似乎没有类似问题？似乎是受到网络姿势和地域的影响？

解决方案：采用CDN技术，在多地针对不同网络运营商配置相应的cdn缓存服务器，用户对图片或者js等静态资源文件的访问自动路由到最近的、负载最低的缓存服务器获取资源。

结果：天南地北中国内外的考拉用户们都可以享受同等的快捷访问享受了！

 

**问题3、考拉活动页的底层依赖之一——商品服务调用量太大了，集群负载饱和，网卡流量爆满！**

原因：考拉活动页每次都调用商品服务查询数据，负载过高。每条商品的数据量较大，加上访问频率高，网卡流量被打满。

业务特点：商品数据量较大，商品信息一般不会频繁变化（可能会经常变化的库存/价格信息等，活动页系统可以容忍短时的不一致）

解决方案：对商品信息的返回结果做了redis缓存（分布式缓存），缓存时间10-20秒。

结果：高峰期调用商品的频率减少了90%以上，活动页业务响应时间缩短50%

 

**问题4：大促主会场的页面0点峰值访问量太大了，redis集群扛不住，扩容成本太高了！**

原因：大促零点存在访问高峰，并发量过高引起redis集群负载饱和，影响响应性能，甚至引发雪崩。

业务特点：流量集中于大促主会场及各主要分会场等少量页面，数据量小。峰值并发高，分布式缓存吃力。

解决方案：使用内存缓存，在每台机器上存放主要页面的框架及未来一小时排期时间片等重要数据（活动页的特点为每一段时间的所展示的数据随着运营配置的不同而不同），无需访问redis，即可获得大部分数据。

结果：减少大促高峰期对redis集群的访问频率，再不用当心大促期间缓存集群容量告警了！